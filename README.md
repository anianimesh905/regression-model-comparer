# ðŸ”¬ streamlit-regression-comparison-app

A Streamlit-based interactive application to **compare regression models** on the **Life Expectancy dataset**. It includes data cleaning, training multiple models, visualizing results, and evaluating performance using metrics and plots.

---

## ðŸ“Œ Features

âœ… Clean and preprocess the Life Expectancy dataset  
âœ… Train and evaluate multiple regression models  
âœ… Visualize model performance using RÂ² scores and prediction accuracy  
âœ… Interactive Streamlit interface for dataset upload, preview, and model comparison  
âœ… Modular and extensible codebase

---

## ðŸ“ Project Structure

```
regression_comparison_app/
â”‚
â”œâ”€â”€ app.py                      # Main Streamlit app
â”œâ”€â”€ clean.py                    # Data cleaning script
â”œâ”€â”€ models.py                   # Train and evaluate regression models
â”œâ”€â”€ utils.py                    # Plotting and helper functions
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Life_Expectancy_Data.csv     # Original dataset
â”‚   â””â”€â”€ life_expectancy_cleaned.csv # Cleaned version (auto-generated)
â”‚
â”œâ”€â”€ images/                    # Optional: Exported plots (if saved)
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project overview (this file)
```

---

## ðŸ“Š Models Implemented

| Model                               | Description                                   |
| ----------------------------------- | --------------------------------------------- |
| **Linear Regression**               | Simple linear fit to data                     |
| **Polynomial Regression**           | Degree 2 regression with feature scaling      |
| **Support Vector Regression (SVR)** | Scaled + kernelized regression                |
| **Decision Tree**                   | Tree-based, non-linear partitioning           |
| **Random Forest**                   | Ensemble of decision trees (boosted accuracy) |

---

## ðŸ“ˆ Visualizations

- **ðŸ“„ Dataset Preview:** Top 5 rows of the dataset
- **ðŸ“Š Metric Table:** MSE and RÂ² for all models
- **ðŸ“ˆ RÂ² Score Bar Chart:** Visual comparison of model RÂ² scores
- **ðŸ“‰ True vs Predicted Scatter Plot:** For each model, shows prediction performance

---

## ðŸš€ How to Run

1. **Clone the repo**

```bash
git clone https://github.com/anianimesh905/streamlit-regression-comparison-app.git
cd streamlit-regression-comparison-app
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Run the app**

```bash
streamlit run app.py
```

---

## ðŸ§ª Upload Your Own Dataset

Want to try it on your own data?

1. Go to the Streamlit sidebar
2. Uncheck **"Use default dataset"**
3. Upload your CSV file

âš ï¸ **Note:** Your file should include a continuous target column like `Life expectancy`.

---

## ðŸ§¹ Data Cleaning Steps

- Drops irrelevant columns (`Country`, `Year`, `Status`)
- Removes rows with too many missing values
- Drops zero-variance columns
- Saves a cleaned CSV for model training

---

## ðŸ’¡ Insights

- **SVR** and **Random Forest** gave the best performance (highest RÂ²)
- **Polynomial Regression** may overfit if features are not scaled
- **Decision Tree** results can appear smooth due to many feature splits, but behavior is piecewise constant (step-like)

---

## ðŸ“¦ Dependencies

```txt
streamlit
pandas
scikit-learn
matplotlib
seaborn
```

Install all via:

```bash
pip install -r requirements.txt
```

---

## ðŸ“¸ Sample Screenshot

> _You can include a sample screenshot from your app UI (optional)_

---

## ðŸ“š Dataset Source

[Life Expectancy (WHO)](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who)

> The dataset includes socio-economic and health data from WHO reports.

---

## ðŸ“‚ To-Do / Extensions

- [ ] Add Ridge/Lasso Regression
- [ ] Export model reports as PDF
- [ ] Deploy on Streamlit Cloud
- [ ] Add feature importance visualizations

---

## ðŸ“œ License

This project is open-source under the [MIT License](LICENSE).

---

## ðŸ™Œ Acknowledgments

- Dataset: World Health Organization (via Kaggle)
- Inspired by regression modeling best practices
